---
title: "Outcome Models"
author: "Lucy D'Agostino McGowan"
format: kakashi-revealjs
footer: "Slides by Dr. Malcom Barret & [Dr. Lucy D'Agostino McGowan](https://lucymcgowan.com)"
---

```{r}
#| label: setup
#| include: false
options(
  tibble.max_extra_cols = 6, 
  tibble.width = 60
)
library(tidyverse)
library(broom)
library(propensity)
library(causaldata)
nhefs_complete_uc <- nhefs_complete |>
  filter(censored == 0)
```

## Outcome Model {.large}

```{r}
#| eval: false
library(broom)

lm(outcome ~ exposure, data = df, weights = wts) |>
  tidy()
```

. . .

`r emo::ji("check")` This will get us the point estimate  

. . .

`r emo::ji("x")` This will get NOT us the correct confidence intervals  

## Estimating Uncertainty

1. Bootstrap
2. Sandwich estimator (on outcome model only)
3. Sandwich estimator (on outcome model + propensity score model)

## 1. Create a function to run your analysis once on a sample of your data

::: {.small}

```{r}
#| code-line-numbers: "|1-2|5-13|16-18|21-22"
fit_ipw <- function(split, ...) {
  .df <- analysis(split)
  
  # fit propensity score model
  propensity_model <- glm(
    qsmk ~ sex + 
      race + age + I(age^2) + education + 
      smokeintensity + I(smokeintensity^2) + 
      smokeyrs + I(smokeyrs^2) + exercise + active + 
      wt71 + I(wt71^2), 
    family = binomial(), 
    data = .df
  )
  
  # calculate inverse probability weights
  .df <- propensity_model |>
    augment(type.predict = "response", data = .df) |>
    mutate(wts = wt_ate(.fitted, qsmk, exposure_type = "binary"))
  
  # fit correctly bootstrapped ipw model
  lm(wt82_71 ~ qsmk, data = .df, weights = wts) |>
    tidy()
}
```
:::

## 2. Use {rsample} to bootstrap our causal effect

```{r}
#| code-line-numbers: "|4-8"
#| output-location: slide
library(rsample)

# fit ipw model to bootstrapped samples
bootstrapped_nhefs <- bootstraps(
  nhefs_complete_uc, 
  times = 1000, 
  apparent = TRUE
)

bootstrapped_nhefs
```

## 2. Use {rsample} to bootstrap our causal effect

```{r}
fit_ipw(bootstrapped_nhefs$splits[[1]])
```

## 2. Use {rsample} to bootstrap our causal effect

```{r}
#| cache: true
#| output-location: slide
#| code-line-numbers: "|2"
ipw_results <- bootstrapped_nhefs |> 
  mutate(boot_fits = map(splits, fit_ipw)) 

ipw_results
```

## 2. Use {rsample} to bootstrap our causal effect

```{r}
#| echo: false
ipw_results |>
  mutate(
    estimate = map_dbl(
      boot_fits,
      # pull the `estimate` for `qsmk` for each fit
      \(.fit) .fit |>
        filter(term == "qsmk") |>
        pull(estimate)
    )
  ) |>
  ggplot(aes(estimate)) +
  geom_histogram(fill = "#D55E00FF", color = "white", alpha = 0.8) + 
  theme_minimal()
```


## 3. Pull out the causal effect

```{r}
#| code-line-numbers: "|2"
#| eval: false
# get t-statistic-based CIs
boot_estimate <- int_t(ipw_results, boot_fits) |> 
  filter(term == "exposure")
```

## *Your Turn*

`r countdown::countdown(minutes = 12)`

### Create a function called `ipw_fit` that fits the propensity score model and the weighted outcome model for the effect between `park_extra_magic_morning` and `wait_minutes_posted_avg`

### Using the `bootstraps()` and `int_t()` functions to estimate the final effect.

## Sandwich estimator

```{r}
#| echo: false
#| eval: true
propensity_model <- glm(
  qsmk ~ sex + 
    race + age + I(age^2) + education + 
    smokeintensity + I(smokeintensity^2) + 
    smokeyrs + I(smokeyrs^2) + exercise + active + 
    wt71 + I(wt71^2), 
  family = binomial(), 
  data = nhefs_complete_uc
)

# calculate inverse probability weights
nhefs_complete_uc <- propensity_model |>
  augment(type.predict = "response", data = nhefs_complete_uc) |>
  mutate(wts = wt_ate(.fitted, qsmk, exposure_type = "binary"))
```

```{r}
#| code-line-numbers: "|2|4|"
library(sandwich)
weighted_mod <- lm(wt82_71 ~ qsmk, data = nhefs_complete_uc, weights = wts)

sandwich(weighted_mod)
```

## Sandwich Estimator

```{r}
robust_var <- sandwich(weighted_mod)[2, 2]
point_est <- coef(weighted_mod)[2]
lb <- point_est - 1.96 * sqrt(robust_var)
ub <- point_est + 1.96 * sqrt(robust_var)
lb
ub
```

## Sandwich Estimator with `{survey}` package

```{r}
library(survey)

des <- svydesign(
  ids = ~1,
  weights = ~wts,
  data = nhefs_complete_uc
)
```

## Sandwich Estimator with `{survey}` package

```{r}
svyglm(wt82_71 ~ qsmk, des) |>
  tidy(conf.int = TRUE)
```

## *Your Turn*

`r countdown::countdown(minutes = 10)`

### Use the `sandwich` package to calcualte the uncertainty for your weighted model

### Repeat this using the `survey` package

